{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38aa179-f80b-436e-b88c-1170c7076755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import sys \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from skimage import exposure\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "sc.settings.verbosity = 3\n",
    "\n",
    "from matplotlib.pyplot import rc_context\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from functools import reduce\n",
    "from matplotlib import cm, colors\n",
    "import scanorama\n",
    "import seaborn as sns \n",
    "import anndata as ad\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8fa83-297a-4654-80b6-a00ae2a36933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:33:02.059794Z",
     "start_time": "2021-07-14T19:33:01.813689Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25b0be-66df-450a-b5e1-8b98aeacee61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:33:02.282241Z",
     "start_time": "2021-07-14T19:33:02.064739Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import path\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "module_path = str(Path.cwd().parents[0] / \"src\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bc5b6-7059-4dd3-b545-c93ab445b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220b1a-d916-4389-be5c-524abe197d51",
   "metadata": {},
   "source": [
    "# Read info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6176e-10d9-49a9-b5b3-0cf93bc47b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "from functools import partial\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.filters import median\n",
    "from skimage.morphology import disk\n",
    "import skimage.io\n",
    "\n",
    "def get_info(img_folder):\n",
    "    \"\"\"Function returns the info from folder containing multi-cycle staigning on cell\n",
    "\n",
    "    Args:\n",
    "        img_folder (str) : imgage folder path to get information\n",
    "        name_dict (dict) : three level dictionnary mapping cycle -> channel -> marker name\n",
    "\n",
    "    Returns:\n",
    "        pandas dataframe with information\n",
    "    \"\"\"\n",
    "    images_path = []\n",
    "    markers = []\n",
    "    rois = []\n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(img_folder):\n",
    "        for name in sorted(filenames):\n",
    "            if 'ome.tiff' not in name:\n",
    "                continue \n",
    "                \n",
    "            roi = dirpath.split('_')[-1]\n",
    "            try:\n",
    "                marker = name.split('_')[2].split('.')[0]\n",
    "                if marker == 'contaminant':\n",
    "                    continue\n",
    "                elif marker == 'DNA':\n",
    "                    if '191Ir' in name:\n",
    "                        marker += '1'\n",
    "                    else:\n",
    "                        marker += '2'\n",
    "            except:continue\n",
    "            \n",
    "            path = os.path.join(dirpath, name)\n",
    "            rois.append(roi)\n",
    "            markers.append(marker)\n",
    "            images_path.append(path)\n",
    "            \n",
    "    info = {\n",
    "        \"ROI\": rois,\n",
    "        \"Marker\": markers,\n",
    "        \"Path\": images_path,\n",
    "    }\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc9a52-838b-4e24-9100-c9889e1d8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ROI = data_dir / 'ROI_new'\n",
    "df = get_info(data_ROI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74317eb2-3057-44ce-8936-fed47c45283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.Marker.isin(['DNA1', 'DNA2'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db06335-c2f1-430c-9508-be840c3b625d",
   "metadata": {},
   "source": [
    "# Read images, process and save to h5 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95cc01-af09-497f-abb4-0915da920cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from skimage.util import img_as_ubyte \n",
    "\n",
    "def contrast_streching(img):\n",
    "    p2, p98 = np.percentile(img, (1,99))\n",
    "    return exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "\n",
    "def read_img(path:str) -> np.ndarray:\n",
    "    '''\n",
    "    Read image from path\n",
    "    '''\n",
    "    img = io.imread(path, as_gray=True)\n",
    "    img = contrast_streching(img)\n",
    "    img = img_as_ubyte(img)\n",
    "    return img\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def get_NN(data, n):\n",
    "    fit = NearestNeighbors(n_neighbors=n).fit(data)\n",
    "    distances, indices = fit.kneighbors(data)\n",
    "\n",
    "    return distances, indices\n",
    "\n",
    "def filter_img_knn(img, n=25, th=3.5):\n",
    "    # Get avg distances per positive expressed pixels\n",
    "    x, y = np.where(img > 0)\n",
    "    values = img[x,y]\n",
    "    \n",
    "    data = np.column_stack((x,y))\n",
    "    distances, indices = get_NN(data, n)\n",
    "    # avg_dist = np.average(distances, axis=1, weights=values[indices])\n",
    "    avg_dist = np.average(distances, axis=1)\n",
    "        \n",
    "    filter_ind = avg_dist > th\n",
    "    unique, counts = np.unique(filter_ind, return_counts=True)\n",
    "    print(unique, counts)\n",
    "    x_fil = x[filter_ind]\n",
    "    y_fil = y[filter_ind]\n",
    "\n",
    "    img_fil = img.copy()\n",
    "    img_fil[x_fil, y_fil] = 0\n",
    "    \n",
    "    return img_fil\n",
    "\n",
    "def save_hdf5(path:str, name:str, data: np.ndarray, attr_dict= None, mode:str='a') -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        chunk_shape = (1, ) + data_shape[1:]\n",
    "        max_shape = (data_shape[0], ) + data_shape[1:]\n",
    "        dset = hf.create_dataset(name, shape=data_shape, maxshape=max_shape, chunks=chunk_shape, dtype=data_type, compression=\"gzip\")\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f'Dataset {name} exists')\n",
    "        \n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e362f4-b2b0-4f47-aaf0-e14c77b12c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupby('ROI')\n",
    "h5_data = data_ROI / f'TMA.hdf5'\n",
    "\n",
    "for name, df_group in group:\n",
    "    # Read images\n",
    "    paths = df_group.Path.tolist()\n",
    "    imgs = joblib_loop(read_img, paths)\n",
    "    imgs = joblib_loop(filter_img_knn, imgs)\n",
    "    imgs=np.stack(imgs, axis=0)\n",
    "    # read markeabs    \n",
    "    markers = df_group.Marker.tolist()\n",
    "    print(len(markers))\n",
    "    #Save h5\n",
    "    save_hdf5(h5_data, name, imgs, {'labels': markers})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d492996-19c3-4250-95bd-60abf1d41fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
